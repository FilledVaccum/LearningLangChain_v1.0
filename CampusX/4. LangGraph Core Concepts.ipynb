{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c32f6d-091b-44fe-a6aa-b970b0c9c298",
   "metadata": {},
   "source": [
    "# What is LangGraph?\n",
    "\n",
    "1. It is an orcgestration framework for building **intelligent, stateful and multi-step** LLM workflows.\n",
    "2. It Enables Advance Features like **Parallelism, loops, branching, memory and resumability** making it an ideal candidate and production-grade AI Application.\n",
    "3. It models your **logic as a graph of nodes(task)** and **edges (routing)** instead of linear chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef40f4-566f-4d48-84e3-fb45c5828735",
   "metadata": {},
   "source": [
    "## 1.1 What is LLM Workflow?\n",
    "\n",
    "1. LLM workflows are a step by step process which we can build complex LLM application\n",
    "2. Each step in the workflow performs a distinct task - Such as Prompting, reasoning, tool callling, memory access, or decision making\n",
    "3. Workflow can be linear, parallel, branched or looped, allowing for complex behaviours like retries, multi-agent communication or tool augmented reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0010c1-a865-4d0a-a9c2-838d9d6b41fc",
   "metadata": {},
   "source": [
    "## 2. Common Workflows\n",
    "![alt text](./agent_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7439ee-2ba6-4bd2-8155-b0dd8371822e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:19:58.316372Z",
     "iopub.status.busy": "2026-01-16T08:19:58.315209Z",
     "iopub.status.idle": "2026-01-16T08:19:58.320290Z",
     "shell.execute_reply": "2026-01-16T08:19:58.319774Z",
     "shell.execute_reply.started": "2026-01-16T08:19:58.316353Z"
    }
   },
   "source": [
    "## 3.2 Graphs, Nodes and Edges\n",
    "\n",
    "At its core, LangGraph models agent workflows as graphs. You define the behavior of your agents using three key components:\n",
    "\n",
    "    Nodes: Functions that encode the logic of your agents. They receive the current state as input, perform some computation or side-effect, and return an updated state.\n",
    "    Edges: Functions that determine which Node to execute next based on the current state. They can be conditional branches or fixed transitions.\n",
    "    State: A shared data structure that represents the current snapshot of your application. It can be any data type, but is typically defined using a shared state schema.\n",
    "\n",
    "By composing Nodes and Edges, you can create complex, looping workflows that evolve the state over time. The real power, though, comes from how LangGraph manages that state. To emphasize: Nodes and Edges are nothing more than functions – they can contain an LLM or just good ol’ code. In short: nodes do the work, edges tell what to do next. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b6170-843d-42ee-aac0-8db1548ffaec",
   "metadata": {},
   "source": [
    "```\n",
    "LangGraph’s underlying graph algorithm uses message passing to define a general program. When a Node completes its operation, it sends messages along one or more edges to other node(s). These recipient nodes then execute their functions, pass the resulting messages to the next set of nodes, and the process continues. Inspired by Google’s Pregel system, the program proceeds in discrete “super-steps.”\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a75d6-1824-4f40-9add-06d5b46e81b7",
   "metadata": {},
   "source": [
    "```\n",
    "A super-step can be considered a single iteration over the graph nodes. Nodes that run in parallel are part of the same super-step, while nodes that run sequentially belong to separate super-steps. At the start of graph execution, all nodes begin in an inactive state. A node becomes active when it receives a new message (state) on any of its incoming edges (or “channels”). The active node then runs its function and responds with updates. At the end of each super-step, nodes with no incoming messages vote to halt by marking themselves as inactive. The graph execution terminates when all nodes are inactive and no messages are in transit.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd9153-503d-479e-81ca-72e56a5c46d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:28:59.119567Z",
     "iopub.status.busy": "2026-01-16T08:28:59.119216Z",
     "iopub.status.idle": "2026-01-16T08:28:59.124452Z",
     "shell.execute_reply": "2026-01-16T08:28:59.123534Z",
     "shell.execute_reply.started": "2026-01-16T08:28:59.119549Z"
    }
   },
   "source": [
    "### 3.2.1 Nodes\n",
    "\n",
    "\n",
    "In LangGraph, nodes are Python functions (either synchronous or asynchronous) that accept the following arguments:\n",
    "\n",
    "    1. state – The state of the graph\n",
    "    2. config – A RunnableConfig object that contains configuration information like thread_id and tracing information like tags\n",
    "    3. runtime – A Runtime object that contains runtime context and other information like store and stream_writer\n",
    "\n",
    "Similar to NetworkX, you add these nodes to a graph using the add_node method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49351698-472b-4447-83b0-adda135de05f",
   "metadata": {},
   "source": [
    "#### START node\n",
    "The START Node is a special node that represents the node that sends user input to the graph. The main purpose for referencing this node is to determine which nodes should be called first.\n",
    "\n",
    "```python\n",
    "    from langgraph.graph import START\n",
    "\n",
    "    graph.add_edge(START, \"node_a\")\n",
    "```\n",
    "\n",
    "#### END node\n",
    "The END Node is a special node that represents a terminal node. This node is referenced when you want to denote which edges have no actions after they are done.\n",
    "\n",
    "```python\n",
    "    from langgraph.graph import END\n",
    "    \n",
    "    graph.add_edge(\"node_a\", END)\n",
    "```\n",
    "\n",
    "\n",
    "#### Node caching\n",
    "LangGraph supports caching of tasks/nodes based on the input to the node. To use caching:\n",
    "\n",
    "    * Specify a cache when compiling a graph (or specifying an entrypoint)\n",
    "    * Specify a cache policy for nodes. Each cache policy supports:\n",
    "        - key_func used to generate a cache key based on the input to a node, which defaults to a hash of the input with pickle.\n",
    "        - ttl, the time to live for the cache in seconds. If not specified, the cache will never expire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a0b45-d748-4390-9aa6-cae9195e3b78",
   "metadata": {},
   "source": [
    "## 3.3 State\n",
    "\n",
    "The first thing you do when you define a graph is define the **State of the graph**. The State consists of the schema of the graph as well as reducer functions which specify how to apply updates to the state. The schema of the State will be the input schema to all Nodes and Edges in the graph, and can be either a **TypedDict or a Pydantic** model. All Nodes will emit updates to the State which are then applied using the specified reducer function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2fc53f-4dca-4fd0-b570-7c6c54778f26",
   "metadata": {},
   "source": [
    "## 3.4 Reducer\n",
    "Reducers are key to understanding how updates from nodes are applied to the State. **Each key in the State has its own independent reducer function**. If no reducer function is explicitly specified then it is assumed that all updates to that key should override it. There are a few different types of reducers, starting with the default type of reducer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a34789f-a5d6-4484-97d2-8e070f031586",
   "metadata": {},
   "source": [
    "## 4 LangGraph Execution Model\n",
    "\n",
    "*1-Graph Definition*\n",
    "\n",
    "\n",
    "\n",
    "You define:\n",
    "\n",
    "\n",
    "\n",
    "- The state schema\n",
    "\n",
    "- Nodes\n",
    "\n",
    "- Edges\n",
    "\n",
    "\n",
    "\n",
    "*2-Compilation*\n",
    "\n",
    "\n",
    "\n",
    "You call `.compile()` on the `StateGraph`\n",
    "\n",
    "\n",
    "\n",
    "This checks the graph structure and prepares it for execution\n",
    "\n",
    "\n",
    "\n",
    "*3-Invocation*\n",
    "\n",
    "\n",
    "\n",
    "You run the graph with `.invoke(intial_state)`\n",
    "\n",
    "\n",
    "\n",
    "LangGraph sends the initial state as a message to the entry node(s).\n",
    "\n",
    "\n",
    "\n",
    "*4-Super step Begin*\n",
    "\n",
    "\n",
    "\n",
    "Execution proceeds in rounds\n",
    "\n",
    "\n",
    "\n",
    "*5-Message passing & Node activation*\n",
    "\n",
    "\n",
    "\n",
    "The messages are passed to downstream nodes via edges\n",
    "\n",
    "\n",
    "\n",
    "Nodes that receive messages become active for the next round\n",
    "\n",
    "\n",
    "\n",
    "*6-Halting condition*\n",
    "\n",
    "\n",
    "\n",
    "Execution stops when\n",
    "\n",
    "\n",
    "\n",
    "- No nodes are active, and\n",
    "\n",
    "- No messages are in transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab71182-4a3f-432f-91ae-338f9b14bfec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
